{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test nbdev\n",
    "\n",
    "> This is a project to test out nbdev with some simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    \"\"\"Returns stemmed or lemmatized text with removed punctuation and stopwords\n",
    "    works on Dutch and English \"\"\"\n",
    "    \n",
    "    preprocessed_text = []    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "        \n",
    "    text = re.sub(r'[^\\w\\d\\s\\']+', '', text)\n",
    "    doc = nlp(text)\n",
    "        \n",
    "    for token in doc:\n",
    "        if token.text not in stopwords.words('english'):\n",
    "            preprocessed_text.append(token.lemma_)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_freq(documents):\n",
    "    \n",
    "    \"Returns list with vocabulary frequencies per document and a vocabalury list\"\n",
    "    \n",
    "    document_frequency = []\n",
    "    vocab = []\n",
    "\n",
    "    for page in documents:\n",
    "        pre = preprocess(page)\n",
    "        document_frequency.append(Counter(pre))\n",
    "        vocab = vocab + pre\n",
    "    \n",
    "    vocab = list(set(vocab))\n",
    "    return document_frequency, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def form_matrix(doc_freq, vocabulary):\n",
    "\n",
    "    \"\"\"\"Returns matrix with td-idf vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    M = []\n",
    "    \n",
    "    for doc in doc_freq:\n",
    "        arr = np.zeros(len(vocabulary))\n",
    "\n",
    "        for word in doc.keys():\n",
    "            tf = doc[word] / (sum(doc.values()))\n",
    "            freq = 0\n",
    "            for doc1 in doc_freq:\n",
    "                if word in doc1.keys():\n",
    "                    freq+=1\n",
    "    \n",
    "            idf = math.log(len(doc_freq)/(freq+1))\n",
    "            tfidf = tf * idf\n",
    "            tfidf_arr = np.array([tfidf])\n",
    "            index = vocabulary.index(word) \n",
    "            np.put(arr, index, tfidf_arr)\n",
    "\n",
    "        M.append(arr)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_query_vec(preprocessed_query, vocab, doc_freq):\n",
    "\n",
    "    \"Retun tf-idf vector of input query\"\n",
    "    \n",
    "    \n",
    "    counter = Counter(preprocessed_query)\n",
    "    vector = np.zeros(len(vocab))\n",
    "\n",
    "    for word in preprocessed_query:\n",
    "\n",
    "        tf = counter[word] * sum(counter.values())\n",
    "        freq = 0\n",
    "        for doc in doc_freq:\n",
    "            if word in doc.keys():\n",
    "                freq+=1\n",
    "        idf = math.log(len(doc_freq)/ (freq+1))\n",
    "        tfidf = tf * idf\n",
    "        tfidf_arr = np.array([tfidf])        \n",
    "        if word in vocab:\n",
    "            index = vocab.index(word) \n",
    "            np.put(vector, index, tfidf_arr)\n",
    "    \n",
    "    return vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cos_sim(matrix, vector):\n",
    "    \n",
    "    \"Returns 10 most similar documents based on cosine similarity between documents and query vector\"\n",
    "    \n",
    "    cos_sim = []\n",
    "    for vec in matrix:\n",
    "        cos = np.dot(vec, vector) / (np.linalg.norm(vec) * np.linalg.norm(vector))\n",
    "        cos_sim.append(cos)\n",
    "    \n",
    "    array = np.array(cos_sim)\n",
    "    sort_index = np.argsort(array)[::-1][:10]\n",
    "    return sort_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "text =  \"Hello world!\"\n",
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "assert preprocess(\"Anne lives in Spain\") == [\"Anne\", \"live\",\"Spain\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'work', 'world', 'NLP', 'fun', 'bank', 'hello']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "documents = [\"Hello world\", \"NLP is fun\", \"We work at the bank\"]\n",
    "\n",
    "document_frequency, vocabulary = get_freq(documents)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
